{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fE1kYhf2o0no",
        "aYouIUpFo_wc",
        "Z2wkp6zLplwp",
        "izX-W7Q9qJ5a",
        "z-9PlhpLqUhN",
        "QSOE7OderkZQ",
        "SUDEmbP_rxIg",
        "gWwmdwc1sTcA",
        "uu0yKWyAsfoA",
        "bsdVw5cmnkSJ",
        "DvnBSSqDnty-",
        "uKxKJxXtoAfz",
        "ETA1at3SoE2g"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Projeto II - Processamento de Linguagem Natural\n",
        "\n",
        "**Nome**: Guilherme Ferreira Galdino <br>\n",
        "**RA**  : 11201811063 \n",
        "\n",
        "## Descrição\n",
        "\n",
        "Chatbot criado para obter informações de diversos jogos, como review, feedbacks, recomendações e dúvidas em geral."
      ],
      "metadata": {
        "id": "Q6ztLxiJlS_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://first-bucket-course-alura.s3.us-east-2.amazonaws.com/fluxo.png'>"
      ],
      "metadata": {
        "id": "-Qz665TAxrF_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. O Chatbot recupera a frase do usuario e tenta descobrir qual o contexto/topico que se trata.\n",
        "2. Nos topicos, existem 5 possibilidades: \n",
        "<ul>\n",
        "  <li>2.1 Saudações</li>\n",
        "  <li>2.2 Review/Resumo</li>\n",
        "  <li>2.3 Feedback</li>\n",
        "  <li>2.4 Recomendacao</li>\n",
        "  <li>2.5 Perguntas e respostas</li>\n",
        "</ul>\n",
        "3. Em saudações irá reconhecer os padrões utilizando unigramas e bigramas. Caso corresponda com aqueles previamente inseridos, irá responder o cumprimento com as opções de reposta de forma aleatória.\n",
        "4. Review/Resumo\n",
        "<ul>\n",
        "<li>4.1 o chatbot tentará reconhecer o nome do jogo</li>\n",
        "<li>4.2 obterá o nome do jogo mais próximo da base do kaggle</li>\n",
        "<li>4.3 irá fazer a raspagem da review do jogo recuperado no site gamespot</li>\n",
        "<li>4.4 executará a sumarização da review</li>\n",
        "<li>4.5 devido o site ser em inglês, será feito a tradução para o português</li>\n",
        "<li>4.6 por fim, mostra a resposta gerada no processo</li>\n",
        "</ul>\n",
        "5. Feedback\n",
        "<ul>\n",
        "<li>5.1 o chatbot tentará reconhecer o nome do jogo</li>\n",
        "<li>5.2 obterá o nome do jogo mais próximo da base do kaggle</li>\n",
        "<li>5.3 irá fazer a raspagem no mesmo site do gamespot, porém obtendos os comentários dos usuários na plataforma</li>\n",
        "<li>5.4 une todos os comentários e realiza a sumarização, para não ultrapassar o limite que o modelo de anlise de sentimento estabelece</li>\n",
        "<li>5.5 aplica o modelo de analise sentimento para obter se os comentarios são positivos, neutros ou negativos</li>\n",
        "<li>5.6 retorna a resposta gerada no processo</li>\n",
        "</ul>\n",
        "6. Recomendação\n",
        "<ul>\n",
        "<li>6.1 o chatbot tentará reconhecer o nome do jogo</li>\n",
        "<li>6.2 obterá o nome do jogo mais próximo da base do kaggle</li>\n",
        "<li>6.3 com a mesma base do kaggle, obterá informações dos outros jogos sobre o gênero e a plataforma</li>\n",
        "<li>6.4 fará a comparação por similaridade do jogo mencionado com os restantes da base</li>\n",
        "<li>6.5 retorna os 5 jogos mais semelhantes com aquele mencionado</li>\n",
        "</ul>\n",
        "7. Perguntas e respostas\n",
        "<ul>\n",
        "<li>7.1 o chatbot tentará reconhecer o nome do jogo</li>\n",
        "<li>7.2 obterá o nome do jogo mais próximo da base do kaggle</li>\n",
        "<li>7.3 realiza uma busca no site do wikipedia sobre o determinado jogo</li>\n",
        "<li>7.4 realiza a vetorização de todos os textos presentes na página</li>\n",
        "<li>7.5 encontra as similaridades das frases com a pergunta feita</li>\n",
        "<li>7.6 retorna a resposta que se aproximou mais com a pergunta</li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "ij6271UmzxRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencias"
      ],
      "metadata": {
        "id": "0Mfb3h6CnfoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QHeSZ7puo0E",
        "outputId": "af9a0cb9-cec4-4b49-aa30-a2abd8e54de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==3.1.0a0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MuUv1RcuoJ0",
        "outputId": "eb3e1f34-e2bb-40ff-c556-6e91253d9155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: googletrans==3.1.0a0 in /usr/local/lib/python3.7/dist-packages (3.1.0a0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.7/dist-packages (from googletrans==3.1.0a0) (0.13.3)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.2.0)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2022.8.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2022.6.15)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aacjglatvUsX",
        "outputId": "3a0343be-8e30-42bd-e613-868b242a13b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!spacy download pt_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uyMPK36wIBz",
        "outputId": "b2db24ae-5c7b-4e7a-9196-d61ef17a76ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-28 20:24:48.619085: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pt-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.4.0/pt_core_news_sm-3.4.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.0 MB 12.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from pt-core-news-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (4.64.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->pt-core-news-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from collections import Counter \n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from transformers import pipeline \n",
        "from urllib.parse import quote_plus\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy \n",
        "import googletrans\n",
        "import csv\n",
        "import json "
      ],
      "metadata": {
        "id": "uElmkHjBnZgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nlp = spacy.load('pt_core_news_sm')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "stopwords_pt = spacy.lang.pt.stop_words.STOP_WORDS\n",
        "\n",
        "sentiment_task = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "URL_WIKIPEDIA = 'https://pt.wikipedia.org'\n",
        "URL_GAMESPOT = 'https://www.gamespot.com'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntzatTWqomKP",
        "outputId": "6ab78e72-b55e-48e8-9332-b708c1c768de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PLN"
      ],
      "metadata": {
        "id": "8Yq6LWXDodUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre processamento"
      ],
      "metadata": {
        "id": "fE1kYhf2o0no"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stop_words(tokens, language = 'en'):\n",
        "    stop_words = stopwords\n",
        "    if language == 'pt':\n",
        "        stop_words = stopwords_pt\n",
        "\n",
        "    new_text = []\n",
        "    for token in tokens:\n",
        "        if token not in stop_words and token not in string.punctuation:\n",
        "            new_text.append(token)\n",
        "\n",
        "    return new_text"
      ],
      "metadata": {
        "id": "_XTDxM3bogTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_processing(text, stopwords = 'en', lemma = True):\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", \" \", text)\n",
        "\n",
        "    text = re.sub(r\" +\", ' ', text)\n",
        "\n",
        "    tokens = []\n",
        "    for token in nltk.word_tokenize(text):\n",
        "        tokens.append(token)\n",
        "\n",
        "    new_text = remove_stop_words(tokens, stopwords)\n",
        "\n",
        "    text = ' '.join([str(element) for element in new_text])\n",
        "\n",
        "    if lemma:\n",
        "        doc = nlp(text)\n",
        "        list = []\n",
        "        for token in doc:\n",
        "            list.append(token.lemma_)\n",
        "        \n",
        "        text = ' '.join([str(element) for element in list])\n",
        "\n",
        "    return text "
      ],
      "metadata": {
        "id": "sgLLE4-wo5e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sumarizacao"
      ],
      "metadata": {
        "id": "aYouIUpFo_wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score_words(freq_dist):\n",
        "    max_freq = max(freq_dist.values())\n",
        "\n",
        "    for word in freq_dist.keys():\n",
        "        freq_dist[word] = (freq_dist[word]/max_freq)\n",
        "    \n",
        "    return freq_dist"
      ],
      "metadata": {
        "id": "RgLxCZLppC3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_sentences(sents, freq_dist, max_len=30):\n",
        "    sent_scores = {}\n",
        "\n",
        "    for sent in sents:\n",
        "        words = sent.split(' ')\n",
        "        for word in words:\n",
        "            if word.lower() not in freq_dist.keys() or len(words) >= max_len:\n",
        "                continue\n",
        "\n",
        "            if sent in sent_scores.keys():\n",
        "                sent_scores[sent] += freq_dist[word.lower()]\n",
        "            else:\n",
        "                sent_scores[sent] = freq_dist[word.lower()]\n",
        "    \n",
        "    return sent_scores"
      ],
      "metadata": {
        "id": "29Hz7wFypJVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarization(text, k):\n",
        "    clean_text = re.sub('\\n', '', text)\n",
        "    clean_text = re.sub('-', '', clean_text)\n",
        "    clean_text = pre_processing(text)\n",
        "\n",
        "    word_tkn = nltk.word_tokenize(clean_text)\n",
        "    freq_dist = nltk.FreqDist(word_tkn)\n",
        "    freq_dist = score_words(freq_dist)\n",
        "\n",
        "    sent_tkn = nltk.sent_tokenize(text)\n",
        "    sent_scores = score_sentences(sent_tkn, freq_dist)\n",
        "\n",
        "    top_sents = Counter(sent_scores)\n",
        "    tops = top_sents.most_common(k)\n",
        "\n",
        "    summary = ''\n",
        "    for top in tops:\n",
        "        summary += top[0].strip() + ' '\n",
        "\n",
        "    return summary[:-1]"
      ],
      "metadata": {
        "id": "y7AbJxGNpLHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Similaridade"
      ],
      "metadata": {
        "id": "69IquUhxpQuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similarity(sents_pre_process):\n",
        "    tfidf = TfidfVectorizer()\n",
        "    words_vectors = tfidf.fit_transform(sents_pre_process)\n",
        "\n",
        "    similarity = cosine_similarity(words_vectors[-1], words_vectors)\n",
        "\n",
        "    return similarity"
      ],
      "metadata": {
        "id": "p99NN9YOpUDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_similar(content, text):\n",
        "    sents = nltk.sent_tokenize(content)\n",
        "\n",
        "    sents_pre_process = []\n",
        "    for i in range(len(sents)):\n",
        "        sents_pre_process.append(pre_processing(sents[i], stopwords='pt', lemma=True))\n",
        "\n",
        "    text = pre_processing(text, stopwords='pt', lemma=True)\n",
        "    sents_pre_process.append(text)\n",
        "\n",
        "    similarity = get_similarity(sents_pre_process)\n",
        "\n",
        "    sent_idx = similarity.argsort()[0][-2]\n",
        "    similar_vector = similarity.flatten()\n",
        "    similar_vector.sort()\n",
        "    vector_found = similar_vector[-2]\n",
        "\n",
        "    if vector_found != 0:\n",
        "        return sents[sent_idx]\n",
        "    \n",
        "    return None "
      ],
      "metadata": {
        "id": "8AxBmeS2pV9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_similarity(doc):\n",
        "    tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
        "    tfidf_matrix = tf.fit_transform(doc)\n",
        "    doc_sim = cosine_similarity(tfidf_matrix)\n",
        "    doc_sim_df = pd.DataFrame(doc_sim)\n",
        "\n",
        "    return doc_sim_df"
      ],
      "metadata": {
        "id": "KMvm8IK8pZyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def most_games_similarities(game_name, games, doc_sims, top = 5):\n",
        "    game_idx = np.where(games == game_name.lower())[0][0]\n",
        "    game_similarities = doc_sims.iloc[game_idx].values \n",
        "    similar_game_idxs = np.argsort(-game_similarities)[1:top + 1]\n",
        "    similar_games = games[similar_game_idxs]\n",
        "\n",
        "    return similar_games"
      ],
      "metadata": {
        "id": "BwWRPiiapg-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analise de Sentimento"
      ],
      "metadata": {
        "id": "Z2wkp6zLplwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_sentiment_by_score(score):\n",
        "    label = ''\n",
        "    if score > 0.8:\n",
        "        label = 'muito boa'\n",
        "    elif score > 0.4:\n",
        "        label = 'boa'\n",
        "    elif score > 0:\n",
        "        label = 'razoavel'\n",
        "    elif score > -0.4:\n",
        "        label = 'ruim'\n",
        "    elif score > -0.7:\n",
        "        label = 'pessima'\n",
        "    else:\n",
        "        label = 'horrivel'\n",
        "\n",
        "    return label "
      ],
      "metadata": {
        "id": "RjjmVi8YpsJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_analysis(text):\n",
        "    text = summarization(text, 512)\n",
        "\n",
        "    sents = nltk.sent_tokenize(text)\n",
        "    sentiments = sentiment_task(sents)\n",
        "\n",
        "    score = 0\n",
        "    count = 0\n",
        "    for sentiment in sentiments:\n",
        "        label = sentiment['label'].lower()\n",
        "        if label == 'positive':\n",
        "            score += sentiment['score']\n",
        "        else:\n",
        "            score -= sentiment['score']\n",
        "        count += 1\n",
        "    \n",
        "    score = score / count \n",
        "\n",
        "    return get_label_sentiment_by_score(score)"
      ],
      "metadata": {
        "id": "6z4lBFpWp04H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perguntas e repostas"
      ],
      "metadata": {
        "id": "_klMJi7pp-Pp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wiki_content_by_topic(topic):\n",
        "    safe_string = quote_plus(topic)\n",
        "\n",
        "    link = f'https://pt.wikipedia.org/w/index.php?search={safe_string}&title=Especial:Pesquisar&profile=advanced&fulltext=1&searchengineselect=mediawiki&ns0=1'\n",
        "    \n",
        "    dados = urllib.request.urlopen(link)\n",
        "    dados_html = BeautifulSoup(dados, 'lxml')\n",
        "\n",
        "    ul = dados_html.select('#mw-content-text > div.searchresults > ul')[0]\n",
        "    li = ul.find_all('li')[0]\n",
        "    href = li.find('a').attrs['href']\n",
        "\n",
        "    link = URL_WIKIPEDIA + href \n",
        "    dados = urllib.request.urlopen(link)\n",
        "    dados_html = BeautifulSoup(dados, 'lxml')\n",
        "    paragraphs = dados_html.find_all('p')\n",
        "    content = ''\n",
        "    for p in paragraphs:\n",
        "        content += p.text \n",
        "    content = content.lower()\n",
        "\n",
        "    return content"
      ],
      "metadata": {
        "id": "fYdhlZybqBz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def question_answer(text, topic):\n",
        "    content = get_wiki_content_by_topic(topic)\n",
        "    \n",
        "    return get_most_similar(content, text)"
      ],
      "metadata": {
        "id": "ZDBJXAKhqGy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo de Linguagem com N-gramas"
      ],
      "metadata": {
        "id": "izX-W7Q9qJ5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def n_gram_extractor(sentence, n):\n",
        "    grams = []\n",
        "    tokens = re.sub(r'([^\\s\\w]|_)+', ' ', sentence).split()\n",
        "    for i in range(len(tokens)-n+1):\n",
        "        g = ' '.join(tokens[i:i+n])\n",
        "        grams.append(g)\n",
        "\n",
        "    return grams "
      ],
      "metadata": {
        "id": "ijhDnQJPqPVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def n_gram_extractor_range(sentence, start, end):\n",
        "    grams = []\n",
        "    if start == end:\n",
        "        return n_gram_extractor(sentence, start)\n",
        "\n",
        "    for i in range(start, end + 1):\n",
        "        g_n = n_gram_extractor(sentence, i)\n",
        "        grams.extend(g_n)\n",
        "\n",
        "    return grams "
      ],
      "metadata": {
        "id": "F4oJiKvuqRZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traducao"
      ],
      "metadata": {
        "id": "z-9PlhpLqUhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, source = 'en', destination = 'pt'):\n",
        "    translator = googletrans.Translator()\n",
        "\n",
        "    result = translator.translate(sentence, src=source, dest=destination)\n",
        "\n",
        "    return result.text"
      ],
      "metadata": {
        "id": "akPY2N8aqVpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jogos"
      ],
      "metadata": {
        "id": "pJAmQuiQrTS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Review"
      ],
      "metadata": {
        "id": "QSOE7OderkZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getSoup(link):\n",
        "    response = urllib.request.urlopen(link)\n",
        "    html_doc = response.read()\n",
        "    with open('index.html', 'w') as f:\n",
        "        f.write(str(html_doc))\n",
        "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "    \n",
        "    return soup"
      ],
      "metadata": {
        "id": "cGH6sNCPrV85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getLinkReview(name):\n",
        "    safe_string = quote_plus(name)\n",
        "    url = URL_GAMESPOT + f'/search/?q={safe_string}&i=reviews'\n",
        "    soup = getSoup(url)\n",
        "\n",
        "    list = soup.select('#js-sort-filter-results')[0]\n",
        "    game = list.find('li')\n",
        "    link_review = game.find('a')\n",
        "\n",
        "    return URL_GAMESPOT + link_review.get('href')"
      ],
      "metadata": {
        "id": "8-KldQVVrqVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getReview(name):\n",
        "    link_review = getLinkReview(name)\n",
        "    soup = getSoup(link_review)\n",
        "\n",
        "    article = soup.find('article')\n",
        "    content = article.select('div.js-content-entity-body')[0]\n",
        "    paragraphs = content.find_all('p')\n",
        "    \n",
        "    review = ''\n",
        "    for paragraph in paragraphs:\n",
        "        review += paragraph.getText()\n",
        "    \n",
        "    return review "
      ],
      "metadata": {
        "id": "1qqQMIDFrsVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feedback"
      ],
      "metadata": {
        "id": "SUDEmbP_rxIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_item_by_class(list, class_name):\n",
        "    result = ''\n",
        "    for item in list:\n",
        "        try:\n",
        "            classes = item.attrs['class']\n",
        "            cls = ' '.join(classes)\n",
        "            if class_name in cls:\n",
        "                result = item\n",
        "                break \n",
        "        except:\n",
        "            result = ''\n",
        "    \n",
        "    return result "
      ],
      "metadata": {
        "id": "R2AgERt3r2I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_item_by_attr_contains(list, attr, value):\n",
        "    result = ''\n",
        "    for item in list:\n",
        "        try:\n",
        "            atr = item.attrs[attr]\n",
        "            if value in atr:\n",
        "                result = atr\n",
        "                break \n",
        "        except:\n",
        "            result = ''\n",
        "\n",
        "    return result "
      ],
      "metadata": {
        "id": "UUjpdnfHr5p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_list_item_cotains(list, attr, value):\n",
        "    result = []\n",
        "    count = 0\n",
        "    for item in list:\n",
        "        try:\n",
        "            atr = item.attrs[attr]\n",
        "            if value in atr:\n",
        "                result.append(item)\n",
        "        except:\n",
        "            count += 1\n",
        "\n",
        "    return result "
      ],
      "metadata": {
        "id": "evWGC6Hmr7bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_html_comments(soup):\n",
        "    article = soup.find('article')\n",
        "    links = article.find_all('a')\n",
        "    comment_id = get_item_by_attr_contains(links, 'href', 'comments')\n",
        "    \n",
        "    match = re.findall(r'[0-9]', comment_id)\n",
        "    id = ''.join(match)\n",
        "\n",
        "    link_comments = URL_GAMESPOT  + f'/forums/comments/{id}/?subTopic=0&comment_page=1&wrap=1'\n",
        "    response = urllib.request.urlopen(link_comments)\n",
        "    response_json = response.read()\n",
        "    response_json = response_json.decode('ascii')\n",
        "    response_json = json.loads(response_json)\n",
        "    \n",
        "    return response_json['html']"
      ],
      "metadata": {
        "id": "1j1z97PNr9Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_paragraphs_comments(div_comments):\n",
        "    result = []\n",
        "    for div in div_comments:\n",
        "        article = div.find('article')\n",
        "        paragraphs = article.find_all('p')\n",
        "        for p in paragraphs:\n",
        "            result.append(p.getText())\n",
        "    \n",
        "    return result "
      ],
      "metadata": {
        "id": "tfRqUX05r_Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getFeedbacks(name):\n",
        "    link_review = getLinkReview(name)\n",
        "    soup = getSoup(link_review)\n",
        "    html = get_html_comments(soup)\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    divs = soup.find_all('div')\n",
        "    div_comments = get_item_by_class(divs, 'comment-messages')\n",
        "    div_comments = div_comments.find_all('div')\n",
        "    div_comments = get_list_item_cotains(div_comments, 'id', 'js-message')\n",
        "    comments = get_paragraphs_comments(div_comments)\n",
        "\n",
        "    return comments "
      ],
      "metadata": {
        "id": "Mun7EMuTsBUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nomes/Info jogos"
      ],
      "metadata": {
        "id": "gWwmdwc1sTcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_games_names():\n",
        "    file = open('/content/video_game_dataset.csv')\n",
        "    csvReader = csv.reader(file)\n",
        "    data = list(csvReader)\n",
        "\n",
        "    names = []\n",
        "    for item in data:\n",
        "        names.append(item[1])\n",
        "\n",
        "    return names "
      ],
      "metadata": {
        "id": "2UlugrVisWIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_games_names_df():\n",
        "    df = pd.read_csv('/content/video_game_dataset.csv')\n",
        "\n",
        "    names = df['Name'].values\n",
        "    lower = lambda x: x.lower()\n",
        "    vfunc = np.vectorize(lower)\n",
        "    return vfunc(names)\n"
      ],
      "metadata": {
        "id": "l9nCQlXMsaY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_info_games():\n",
        "    df = pd.read_csv('/content/video_game_dataset.csv')\n",
        "\n",
        "    df['info'] = df['Platform'] + ' ' + df['Genre']\n",
        "    info = list(df['info'])\n",
        "\n",
        "    return info"
      ],
      "metadata": {
        "id": "6fX6HJSysc_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reconhecimento Nomes Jogos"
      ],
      "metadata": {
        "id": "uu0yKWyAsfoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_similar_game(words, value):\n",
        "    score = 0\n",
        "    idx = 0\n",
        "    for i, word in enumerate(words):\n",
        "        sents = word.split(' ')\n",
        "        sents.append(value)\n",
        "        similarity = get_similarity(sents)\n",
        "        aux = similarity[0].sum()\n",
        "\n",
        "        if aux > score:\n",
        "            idx = i \n",
        "            score = aux \n",
        "\n",
        "    return (words[idx], score)"
      ],
      "metadata": {
        "id": "iE_x3wykshaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def named_game_recognition(text):\n",
        "    text = pre_processing(text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = remove_stop_words(tokens, 'pt')\n",
        "\n",
        "    text = ' '.join(tokens)\n",
        "    tokens = n_gram_extractor_range(text, 1, 2)\n",
        "    \n",
        "    games = get_games_names()\n",
        " \n",
        "    max_score = 0\n",
        "    game_name = ''\n",
        "    for token in tokens:\n",
        "        name, score = get_most_similar_game(games, token)\n",
        "        if score > max_score:\n",
        "            max_score = score\n",
        "            game_name = name \n",
        "    \n",
        "    if max_score <= 1:\n",
        "        return None \n",
        "\n",
        "    return game_name"
      ],
      "metadata": {
        "id": "2NF4fMdYsknf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getGameName(text):\n",
        "    name = named_game_recognition(text)\n",
        "    \n",
        "    if name is None:\n",
        "        return (False, 'Nao reconheci o nome do jogo. Pode repetir o nome dele ?')\n",
        "    \n",
        "    return (True, name)"
      ],
      "metadata": {
        "id": "wS3S501Wsmpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Topicos"
      ],
      "metadata": {
        "id": "8tZbvJFYmelK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saudacoes"
      ],
      "metadata": {
        "id": "bsdVw5cmnkSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "greetings_entry = ('olá', 'opa', 'oi', 'ola', 'eae', 'de boa', 'tudo certo', 'tudo bom', 'bom dia', 'boa tarde', 'boa noite', 'oba')\n",
        "greetings_response = ('olá', 'opa', 'oi', 'bem-vindo', 'como você está?', 'tudo bem?')"
      ],
      "metadata": {
        "id": "iom973dnqtAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkGreetings(text):\n",
        "    grams = n_gram_extractor_range(text, 1, 2)\n",
        "\n",
        "    for gram in grams:\n",
        "        if gram.lower() in greetings_entry:\n",
        "            return True \n",
        "\n",
        "    return False"
      ],
      "metadata": {
        "id": "3Pi049Tgmghb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greetings(text):\n",
        "    grams = n_gram_extractor_range(text, 1, 2)\n",
        "\n",
        "    for gram in grams:\n",
        "        if gram.lower() in greetings_entry:\n",
        "            return random.choice(greetings_response) \n",
        "\n",
        "    return 'Nao entendi, pode repetir ?'"
      ],
      "metadata": {
        "id": "J-baMDYEtZW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recomendacao"
      ],
      "metadata": {
        "id": "DvnBSSqDnty-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkRecommendation(input):\n",
        "    options = ['recomendacao', 'recomendacoes', 'semelhantes', 'semelhante']\n",
        "\n",
        "    for option in options:\n",
        "        if option in input:\n",
        "            return True \n",
        "    \n",
        "    return False  "
      ],
      "metadata": {
        "id": "n0jn5kL4n2tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommendation(input):\n",
        "    try:\n",
        "        success, result = getGameName(input)\n",
        "        if not success:\n",
        "            update_active_topic('recommendation')\n",
        "            return result \n",
        "\n",
        "        game_name = result \n",
        "        print('recuperando recomendacoes semelhantes ao jogo: ' + game_name)\n",
        "\n",
        "        info = get_info_games()\n",
        "        model = get_model_similarity(info)\n",
        "        games = get_games_names_df()\n",
        "        similar_games = most_games_similarities(game_name, games, model)\n",
        "        \n",
        "        update_active_topic('')\n",
        "        return 'Jogos semelhantes: ' + ', '.join(similar_games)\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "        return 'Nao foi possivel obter a recomendacao'"
      ],
      "metadata": {
        "id": "jcIRJQtqtabz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feedback"
      ],
      "metadata": {
        "id": "uKxKJxXtoAfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkFeedback(input):\n",
        "    options = ['feedback', 'opinioes', 'percepcao']\n",
        "\n",
        "    for option in options:\n",
        "        if option in input:\n",
        "            return True \n",
        "    \n",
        "    return False "
      ],
      "metadata": {
        "id": "_K4fyBWqoB2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feedback(input):\n",
        "    try:\n",
        "        success, result = getGameName(input)\n",
        "        if not success:\n",
        "            update_active_topic('feedback')\n",
        "            return result \n",
        "\n",
        "        game_name = result \n",
        "        print('buscando os feedbacks do jogo: ' + game_name)\n",
        "        feedbacks = getFeedbacks(game_name)\n",
        "        \n",
        "        text = ' '.join(feedbacks)\n",
        "        result = sentiment_analysis(text)\n",
        "\n",
        "        update_active_topic('')\n",
        "        return 'opiniao ' + result + ' do jogo'\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "        return 'Nao foi possivel obter os feedbacks do jogo'"
      ],
      "metadata": {
        "id": "pM94g-bYtltK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Review"
      ],
      "metadata": {
        "id": "ETA1at3SoE2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkReview(input):\n",
        "    options = ['review', 'quero saber', 'informacoes', 'informacao']\n",
        "\n",
        "    for option in options:\n",
        "        if option in input:\n",
        "            return True \n",
        "    \n",
        "    return False  "
      ],
      "metadata": {
        "id": "SLLmfo1woKcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def review(input):\n",
        "    try:\n",
        "        success, result = getGameName(input)\n",
        "        if not success:\n",
        "            update_active_topic('review')\n",
        "            return result \n",
        "\n",
        "        gameName = result \n",
        "        print('recuperando a review do jogo: ' + gameName)\n",
        "        review = getReview(gameName)\n",
        "\n",
        "        short_review = summarization(review, 5)\n",
        "\n",
        "        short_review = translate_sentence(short_review)\n",
        "\n",
        "        update_active_topic('')\n",
        "        return short_review\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "        return 'Nao foi possivel obter a review'"
      ],
      "metadata": {
        "id": "n-2eKeKDtp5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perguntas e respostas"
      ],
      "metadata": {
        "id": "K7VjJoruoShB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkQuestionAnswer(input):\n",
        "    return '?' in input"
      ],
      "metadata": {
        "id": "mF6gL9JHoXHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def questionAnswer(input):\n",
        "    try:\n",
        "        success, result = getGameName(input)\n",
        "        if not success:\n",
        "            update_active_topic('question_answer')\n",
        "            update_input(input)\n",
        "            return result \n",
        "\n",
        "        old_input = get_active_input()\n",
        "        if old_input != '':\n",
        "            input = old_input\n",
        "\n",
        "        game_name = result \n",
        "        print('encontrando a resposta da pergunta = ' + input)\n",
        "        answer = question_answer(input, game_name)\n",
        "\n",
        "        answer = re.sub(r\"\\[[0-9]*\\]\", '', answer)\n",
        "        answer = answer.strip()\n",
        "\n",
        "        update_input('')\n",
        "        if answer is None:\n",
        "            return 'Nao sei responder a pergunta :('\n",
        "\n",
        "        return answer \n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "        return 'Nao foi possivel obter a resposta da pergunta'"
      ],
      "metadata": {
        "id": "m85DadtCtvkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Topicos"
      ],
      "metadata": {
        "id": "KiGqk7k-uELj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics = { \n",
        "    'greetings' : (checkGreetings, greetings), \n",
        "    'recommendation' : (checkRecommendation, recommendation),\n",
        "    'feedback' : (checkFeedback, feedback),\n",
        "    'review' : (checkReview, review),\n",
        "    'question_answer' : (checkQuestionAnswer, questionAnswer),\n",
        "    'active' : '',\n",
        "    'input' : ''\n",
        "}\n"
      ],
      "metadata": {
        "id": "vDlAgUfouJES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_topic(input):\n",
        "    active_topic = get_active_topic()\n",
        "    if active_topic != '':\n",
        "        return active_topic\n",
        "\n",
        "    for key, value in topics.items():\n",
        "        if isinstance(value, str):\n",
        "            continue\n",
        "\n",
        "        check = value[0]\n",
        "        if check(input):\n",
        "            return key\n",
        "        \n",
        "    return None "
      ],
      "metadata": {
        "id": "aRCsnAtRuQWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(input, topic):\n",
        "    response = topics[topic][1]\n",
        "    return response(input)"
      ],
      "metadata": {
        "id": "iPeHHMivuTCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chatbot"
      ],
      "metadata": {
        "id": "yiQGt9QOmsIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def output(input, topic):\n",
        "    if topic is None:\n",
        "        return 'Desculpe, mas nao entendi. Pode repetir ?'\n",
        "\n",
        "    response = get_response(input, topic)\n",
        "\n",
        "    return response \n"
      ],
      "metadata": {
        "id": "JolTzk__m_IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "    print(\"(escreva 'sair' para finalizar)\")\n",
        "    print(\"Ola, sou um chatbot e vou responder perguntas sobre jogos: \")\n",
        "\n",
        "    while True:\n",
        "        user_input = input('Usuario: ')\n",
        "        user_input = user_input.lower()\n",
        "\n",
        "        if user_input == 'sair':\n",
        "            print('Ate breve!')\n",
        "            break \n",
        "        \n",
        "        topic = get_topic(user_input)\n",
        "        response = output(user_input, topic)\n",
        "        print('Chatbot:', response)\n",
        "        "
      ],
      "metadata": {
        "id": "IfgWrBy-mtfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRoHvvDqx3Rw",
        "outputId": "7be056dd-0a7b-44d9-cf0a-4c0501ecd132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(escreva 'sair' para finalizar)\n",
            "Ola, sou um chatbot e vou responder perguntas sobre jogos: \n",
            "Usuario: oi\n",
            "Chatbot: como você está?\n",
            "Usuario: bom dia\n",
            "Chatbot: opa\n",
            "Usuario: quero saber sobre o fifa\n",
            "recuperando a review do jogo: FIFA 16\n",
            "Chatbot: As inclinações e fraquezas do ano passado - ritmo, bolas exageradas, comportamento enlouquecedor do defensor - foram tomadas com severidade, na medida em que jogar FIFA 16 parece aprender um novo jogo. A postura do caranguejo que protege a bola não oferece mais uma defesa impenetrável; é mais fácil contornar os jogadores com a posse da bola e depois colocar um pé nela. Os tackles de slide recuperaram um pouco da antiga potência; os jogadores realmente deslizam novamente, o que significa que é possível ganhar a bola de uma distância inesperada. O Draft tira o prazer de construir uma equipe - reunindo uma química forte, a emoção de abrir pacotes - e oferece isso a você sem a necessidade de separar sua equipe principal. Custa 15.000 moedas (ou 300 microtransações FIFA points) para entrar e, claro, o modo Draft é, no final das contas, sobre ganhar mais dinheiro.\n",
            "Usuario: quais sao as opinioes sobre o mario \n",
            "buscando os feedbacks do jogo: Super Mario Bros.\n",
            "Chatbot: opiniao boa do jogo\n",
            "Usuario: recomendacoes semelhantes ao zelda\n",
            "recuperando recomendacoes semelhantes ao jogo: The Legend of Zelda: Ocarina of Time\n",
            "Chatbot: Jogos semelhantes: goldeneye 007, super smash bros., pokemon stadium, donkey kong 64, super mario 64\n",
            "Usuario: recomendacoes do batman\n",
            "recuperando recomendacoes semelhantes ao jogo: Batman: Arkham City\n",
            "Chatbot: Jogos semelhantes: batman: arkham city, resident evil 5, assassin's creed ii, grand theft auto iv, the last of us\n",
            "Usuario: quando foi publicado o batman ?\n",
            "encontrando a resposta da pergunta = quando foi publicado o batman ?\n",
            "Chatbot: o primeiro jogo, batman: arkham asylum (2009), foca-se na luta de batman para tentar prevenir que o coringa destrua gotham city depois de assumir o controle do asilo arkham.\n",
            "Usuario: quem desenvolveu o mario bros ?\n",
            "encontrando a resposta da pergunta = quem desenvolveu o mario bros ?\n",
            "Chatbot: super mario bros. foi desenvolvido para um cartucho de 256 kilobits.\n",
            "Usuario: sair\n",
            "Ate breve!\n"
          ]
        }
      ]
    }
  ]
}